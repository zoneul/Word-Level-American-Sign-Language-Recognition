{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q mediapipe==0.10.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landmark Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hand = list(range(21))\n",
    "\n",
    "filtered_pose = [11, 12, 13, 14, 15, 16]\n",
    "\n",
    "filtered_face = [0, 4, 7, 8, 10, 13, 14, 17, 21, 33, 37, 39, 40, 46, 52, 53, 54, 55, 58,\n",
    "                 61, 63, 65, 66, 67, 70, 78, 80, 81, 82, 84, 87, 88, 91, 93, 95, 103, 105,\n",
    "                 107, 109, 127, 132, 133, 136, 144, 145, 146, 148, 149, 150, 152, 153, 154,\n",
    "                 155, 157, 158, 159, 160, 161, 162, 163, 172, 173, 176, 178, 181, 185, 191,\n",
    "                 234, 246, 249, 251, 263, 267, 269, 270, 276, 282, 283, 284, 285, 288, 291,\n",
    "                 293, 295, 296, 297, 300, 308, 310, 311, 312, 314, 317, 318, 321, 323, 324,\n",
    "                 332, 334, 336, 338, 356, 361, 362, 365, 373, 374, 375, 377, 378, 379, 380,\n",
    "                 381, 382, 384, 385, 386, 387, 388, 389, 390, 397, 398, 400, 402, 405, 409,\n",
    "                 415, 454, 466, 468, 473]\n",
    "\n",
    "HAND_NUM = len(filtered_hand)\n",
    "POSE_NUM = len(filtered_pose)\n",
    "FACE_NUM = len(filtered_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp.solutions.hands.Hands()\n",
    "pose = mp.solutions.pose.Pose()\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "\n",
    "def get_frame_landmarks(frame):\n",
    "    \n",
    "    all_landmarks = np.zeros((HAND_NUM * 2 + POSE_NUM + FACE_NUM, 3))\n",
    "    \n",
    "    def get_hands(frame):\n",
    "        results_hands = hands.process(frame)\n",
    "        if results_hands.multi_hand_landmarks:\n",
    "            for i, hand_landmarks in enumerate(results_hands.multi_hand_landmarks):\n",
    "                if results_hands.multi_handedness[i].classification[0].index == 0: \n",
    "                    all_landmarks[:HAND_NUM, :] = np.array(\n",
    "                        [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]) # right\n",
    "                else:\n",
    "                    all_landmarks[HAND_NUM:HAND_NUM * 2, :] = np.array(\n",
    "                        [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]) # left\n",
    "\n",
    "    def get_pose(frame):\n",
    "        results_pose = pose.process(frame)\n",
    "        if results_pose.pose_landmarks:\n",
    "            all_landmarks[HAND_NUM * 2:HAND_NUM * 2 + POSE_NUM, :] = np.array(\n",
    "                [(lm.x, lm.y, lm.z) for lm in results_pose.pose_landmarks.landmark])[filtered_pose]\n",
    "        \n",
    "    def get_face(frame):\n",
    "        results_face = face_mesh.process(frame)\n",
    "        if results_face.multi_face_landmarks:\n",
    "            all_landmarks[HAND_NUM * 2 + POSE_NUM:, :] = np.array(\n",
    "                [(lm.x, lm.y, lm.z) for lm in results_face.multi_face_landmarks[0].landmark])[filtered_face]\n",
    "        \n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        executor.submit(get_hands, frame)\n",
    "        executor.submit(get_pose, frame)\n",
    "        executor.submit(get_face, frame)\n",
    "\n",
    "    return all_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found: WLASL_2024_03_12__18_55_51___Loss_0.49055755138397217___Accuracy_0.8499220013618469.h5 with accuracy 0.8499220013618469\n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing the model files\n",
    "directory = 'Model/'\n",
    "\n",
    "# Get a list of all the model files in the directory\n",
    "model_files = os.listdir(directory)\n",
    "\n",
    "# Initialize variables to keep track of the highest accuracy and the corresponding file\n",
    "highest_accuracy = 0\n",
    "best_model_file = None\n",
    "\n",
    "# Iterate over each model file\n",
    "for model_file in model_files:\n",
    "    if model_file.endswith('.h5') and model_file.startswith('WLASL_'):\n",
    "        # Extract the accuracy from the file name\n",
    "        accuracy_str = model_file.split('___Accuracy_')[1].split('.h5')[0]\n",
    "        accuracy = float(accuracy_str)\n",
    "        \n",
    "        # Check if this model has a higher accuracy than the current highest accuracy\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_model_file = model_file\n",
    "\n",
    "# Check if a best model was found\n",
    "if best_model_file is not None:\n",
    "    # Specify the path to the best model file\n",
    "    best_model_path = os.path.join(directory, best_model_file)\n",
    "    # Load the best model\n",
    "    model = load_model(best_model_path)\n",
    "    print(f\"Best model found: {best_model_file} with accuracy {highest_accuracy}\")\n",
    "else:\n",
    "    print(\"No model files found or no model with higher accuracy found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the word list\n",
    "with open('wordlist.txt', 'r') as f:\n",
    "    word_index = {word:index for index, word in enumerate([line.strip() for line in f])}\n",
    "    reverse_word_index = {index: word for word, index in word_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Level American Sign Language Real-time Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Get the height and width of the frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Get landmarks for the frame\n",
    "    frame_landmarks = get_frame_landmarks(frame)\n",
    "\n",
    "    # Draw landmarks on the frame\n",
    "    for landmark in frame_landmarks:\n",
    "        x = int(landmark[0] * width)\n",
    "        y = int(landmark[1] * height)\n",
    "        cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "    frame_pred = model.predict(np.array([frame_landmarks]), verbose=0)\n",
    "    frame_word_index = np.argmax(frame_pred)\n",
    "    probability = round(np.max(frame_pred)*100,2)\n",
    "    \n",
    "    # Add text to the frame\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, reverse_word_index[frame_word_index] + ': ' + str(probability) + '%', (10, 30), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame with Landmarks', frame)\n",
    "\n",
    "    # Check for the 'q' key to quit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
